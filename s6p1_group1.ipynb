{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LamaHasan1996/food-order/blob/master/s6p1_group1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMRG7qru8G-C"
      },
      "source": [
        "Перед запуском данного борда необходимо сделать следующее:\n",
        "\n",
        "0. Сделать копию борда через меню \"Файл\" / \"File\".\n",
        "1. Выбрать пункт \"Среда выполнения\" или \"Runtime\" и выберите GPU в качестве аппаратного ускорителя в пункте меню \"Сменить среду выполнения\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz1hqb2oWg96"
      },
      "source": [
        "# Инструменты для работы с языком"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXhKw6r2Wg97"
      },
      "source": [
        "... или зачем нужна предобработка.\n",
        "\n",
        "Раньше мы смотрели на светлую сторону анализа данных - построение моделей. Теперь попробуем глубже посмотреть на часть про предобработку данных. Задача предобработки особенно актуальна, если мы имеем дело с текстами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvOWdHcUWg98"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть выборка из твитов.\n",
        "Нам известна эмоциональная окраска каждого твита из выборки: положительная или отрицательная. Задача состоит в построении модели, которая по тексту твита предсказывает его эмоциональную окраску.\n",
        "\n",
        "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
        "\n",
        "Скачиваем выборку ([источник](http://study.mokoron.com/)): [положительные](https://raw.githubusercontent.com/Gavroshe/RuTweetCorp/master/positive.csv), [отрицательные]( https://raw.githubusercontent.com/Gavroshe/RuTweetCorp/master/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYvTkhGnWg98"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Gavroshe/RuTweetCorp/master/positive.csv\n",
        "!wget https://raw.githubusercontent.com/Gavroshe/RuTweetCorp/master/negative.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX-AeH8RWg9-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # библиотека для удобной работы с датафреймами\n",
        "import numpy as np # библиотека для удобной работы со списками и матрицами\n",
        "\n",
        "# библиотека, где реализованы основные алгоритмы машинного обучения\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtGDKFvQYEDO",
        "outputId": "72d9931c-5ef4-47f1-eae1-70b06fd647fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"408906692374446080\";\"1386325927\";\"pleease_shut_up\";\"@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)\";\"1\";\"0\";\"0\";\"0\";\"7569\";\"62\";\"61\";\"0\"\r\n",
            "\"408906692693221377\";\"1386325927\";\"alinakirpicheva\";\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\";\"1\";\"0\";\"0\";\"0\";\"11825\";\"59\";\"31\";\"2\"\r\n",
            "\"408906695083954177\";\"1386325927\";\"EvgeshaRe\";\"RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!\";\"1\";\"0\";\"1\";\"0\";\"1273\";\"26\";\"27\";\"0\"\r\n",
            "\"408906695356973056\";\"1386325927\";\"ikonnikova_21\";\"RT @digger2912: \"\"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\"\" :DD http://t.co/GqG6iuE2…\";\"1\";\"0\";\"1\";\"0\";\"1549\";\"19\";\"17\";\"0\"\r\n",
            "\"408906761416867842\";\"1386325943\";\"JumpyAlex\";\"@irina_dyshkant Вот что значит страшилка :D\n",
            "Но блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D\";\"1\";\"0\";\"0\";\"0\";\"597\";\"16\";\"23\";\"1\"\r\n",
            "\"408906761769598976\";\"1386325943\";\"JustinB94262583\";\"ну любишь или нет? — Я не знаю кто ты бля:D http://t.co/brf9eNg1U6\";\"1\";\"0\";\"0\";\"0\";\"40\";\"6\";\"16\";\"0\"\r\n",
            "\"408906762436481024\";\"1386325943\";\"twinkleAYO\";\"RT @SpoonLamer: Ох,900 :D ну это конечно же @twinkleAYO . Чтобы у нее было много друзей, ведь она такая мимими &lt;3\";\"1\";\"0\";\"1\";\"0\";\"5169\";\"58\";\"43\";\"2\"\r\n",
            "\"408906764114206720\";\"1386325944\";\"pycalyruhog\";\"RT @veregijytaqo: У тебя есть ухажёр? Нет - мои уши не кто не жрёт :D\";\"1\";\"0\";\"2\";\"0\";\"393\";\"112\";\"153\";\"0\"\r\n",
            "\"408906764608749568\";\"1386325944\";\"grishintv\";\"Поприветствуем моего нового читателя @Alexey1789 ;)\";\"1\";\"0\";\"0\";\"0\";\"5872\";\"1387\";\"1431\";\"12\"\r\n"
          ]
        }
      ],
      "source": [
        "!head positive.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_KQDTGzRMdR",
        "outputId": "da3b9825-14c6-4925-f57d-984cf5ce8f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"425137932283158528\";\"1390195756\";\"pazyfevesity\";\"RT @qelasocadij: Скажите пожалуйста, как у человека может быть 1000 одноклассников? O_o\";\"-1\";\"0\";\"1\";\"0\";\"2168\";\"171\";\"132\";\"0\"\r\n",
            "\"425137934443233281\";\"1390195756\";\"Sonya_Star_14\";\"У нас физ ра на улице\n",
            "Пака линт:(\n",
            "Через 45 минут приду пхжааххв\";\"-1\";\"0\";\"0\";\"0\";\"12722\";\"638\";\"567\";\"2\"\r\n",
            "\"425138035089358848\";\"1390195780\";\"evalesana\";\"Нас сегодня отказались принять в сад, типа мы плачем(( #королев пойду ругаться сейчас, по крайне мере выяснять, что за фигня\";\"-1\";\"0\";\"0\";\"0\";\"4101\";\"166\";\"151\";\"6\"\r\n",
            "\"425138243257253888\";\"1390195830\";\"Yanch_96\";\"Но не каждый хочет что то исправлять:( http://t.co/QNODDQzuZ7\";\"-1\";\"0\";\"0\";\"0\";\"1138\";\"32\";\"46\";\"0\"\r\n",
            "\"425138339503943682\";\"1390195853\";\"tkit_on\";\"скучаю так :-( только @taaannyaaa вправляет мозги, но я все равно скучаю\";\"-1\";\"0\";\"0\";\"0\";\"4822\";\"38\";\"32\";\"0\"\r\n",
            "\"425138437684215808\";\"1390195876\";\"ckooker1\";\"Вот и в школу, в говно это идти уже надо(\";\"-1\";\"0\";\"0\";\"1\";\"165\";\"13\";\"16\";\"0\"\r\n",
            "\"425138490452344832\";\"1390195889\";\"LisaBeroud\";\"RT @_Them__: @LisaBeroud Тауриэль, не грусти :( *обнял*\";\"-1\";\"0\";\"1\";\"0\";\"2516\";\"187\";\"265\";\"0\"\r\n",
            "\"425138595251625984\";\"1390195914\";\"sukapavlov\";\"Такси везет меня на работу. Раздумываю приплатить, чтобы меня втащили на пятый этаж. Лифта то нет :(\";\"-1\";\"0\";\"0\";\"0\";\"7778\";\"146\";\"66\";\"5\"\r\n"
          ]
        }
      ],
      "source": [
        "!tail negative.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVsSSqFKbAWL"
      },
      "source": [
        "Откроем файлы и создадим массив из текстов и правильных меток для твитов.\n",
        "Сначала идут положительные твиты, потом отрицательные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBrSNCKVWg9_"
      },
      "outputs": [],
      "source": [
        "# загружаем положительные твиты\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive) # устанавливаем метки\n",
        "\n",
        "\n",
        "# загружаем отрицательные твиты\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative) # устанавливаем метки\n",
        "\n",
        "# соединяем вместе\n",
        "df = pd.concat([positive, negative])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpUb1qcBBMoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "15678cda-267d-4fbd-cd33-5ec9ec7be9be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfjWsULtaGtf"
      },
      "source": [
        "Посмотрим на полученные данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqudQEvUWg-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "125aebfe-bfd2-4335-848f-164b597e6437"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "15931   RT @Blawar_1337: Теперь у нас с @Wake_UA появи...  positive\n",
              "59532   с днём рождения зайка*))) ухх погуляем мы сего...  positive\n",
              "47185   RT @Shumkova0406199: @ann_safina Вов вов вов А...  negative\n",
              "42002   Надо выдернуть звуковую дорожку из \"Доктора Ка...  positive\n",
              "109035  @_hassliebe_ может все таки на этой неделе вер...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79d75349-c487-4acf-aa0f-dbb02584a296\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15931</th>\n",
              "      <td>RT @Blawar_1337: Теперь у нас с @Wake_UA появи...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59532</th>\n",
              "      <td>с днём рождения зайка*))) ухх погуляем мы сего...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47185</th>\n",
              "      <td>RT @Shumkova0406199: @ann_safina Вов вов вов А...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42002</th>\n",
              "      <td>Надо выдернуть звуковую дорожку из \"Доктора Ка...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109035</th>\n",
              "      <td>@_hassliebe_ может все таки на этой неделе вер...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d75349-c487-4acf-aa0f-dbb02584a296')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79d75349-c487-4acf-aa0f-dbb02584a296 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79d75349-c487-4acf-aa0f-dbb02584a296');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8efa460a-2967-4667-902e-7a98fe9cc6d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8efa460a-2967-4667-902e-7a98fe9cc6d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8efa460a-2967-4667-902e-7a98fe9cc6d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0441 \\u0434\\u043d\\u0451\\u043c \\u0440\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u044f \\u0437\\u0430\\u0439\\u043a\\u0430*))) \\u0443\\u0445\\u0445 \\u043f\\u043e\\u0433\\u0443\\u043b\\u044f\\u0435\\u043c \\u043c\\u044b \\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f)))\",\n          \"@_hassliebe_ \\u043c\\u043e\\u0436\\u0435\\u0442 \\u0432\\u0441\\u0435 \\u0442\\u0430\\u043a\\u0438 \\u043d\\u0430 \\u044d\\u0442\\u043e\\u0439 \\u043d\\u0435\\u0434\\u0435\\u043b\\u0435 \\u0432\\u0435\\u0440\\u043d\\u0435\\u0442\\u0441\\u044f?:(\",\n          \"RT @Shumkova0406199: @ann_safina \\u0412\\u043e\\u0432 \\u0432\\u043e\\u0432 \\u0432\\u043e\\u0432 \\u0410\\u0410\\u0410 \\u042f \\u0427\\u0422\\u041e \\u041f\\u0420\\u041e\\u041f\\u0423\\u0421\\u0422\\u0418\\u041b\\u0410 \\u0410\\u0410\\u0410\\u0410 :( \\u0416\\u0418\\u0417\\u041d\\u042c \\u041a\\u041e\\u041d\\u0427\\u0418\\u041b\\u0410\\u0421\\u042c :(:(:( \\n\\u0411\\u0420\\u0410\\u0422\\u0415\\u0426, \\u0412\\u042b \\u0425\\u041e\\u0420\\u041e\\u0428\\u041e \\u0421\\u041c\\u041e\\u0422\\u0420\\u0418\\u0422\\u0415\\u0421\\u042c , \\u0423\\u0414\\u0410\\u0427\\u0418 \\u0412\\u0410\\u041c \\u2026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "df.sample(5, random_state=40)\n",
        "\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubV1-2JjaZuC"
      },
      "source": [
        "Разбиваем данные на обучающую и тестовую выборки с помощью функции ```train_test_split()``` из **sklearn**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RscvM_TWg-F"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1FpQ4Q4rUvO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "b3db917d-f6a8-4d8e-a117-c79a15a285a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66339     negative\n",
              "107381    positive\n",
              "69853     positive\n",
              "65690     positive\n",
              "106504    negative\n",
              "95080     negative\n",
              "42580     positive\n",
              "57282     positive\n",
              "48016     negative\n",
              "94697     negative\n",
              "Name: label, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66339</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107381</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69853</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65690</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106504</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95080</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42580</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57282</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48016</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94697</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McaZZomvBPUj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "38414934-3b97-4a45-d71e-da0892bfb203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "positive    86007\n",
              "negative    84118\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>86007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>84118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpq4QOU5Wg-H"
      },
      "source": [
        "## Baseline: классификация необработанных n-грамм\n",
        "\n",
        "* Сейчас мы попробуем получить преобразование предложений в численный вектор, с которым может работать стандартный алгоритм машинного обучения, такой как логистическая регрессия.\n",
        "* Для этого нам понадобится познакомиться с понятием n-gram - самых мелких элементов предложения, с которыми можно работать.\n",
        "* Подсчитав количество этих n-грам в предложениях, мы получим искомые численные представления."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_7DyyXRWg-K"
      },
      "source": [
        "## Что такое n-граммы:\n",
        "\n",
        "Самые мелкие структуры языка, с которыми мы работаем, называются **n-граммами**.\n",
        "У n-граммы есть параметр n - количество слов, которые попадают в такое представление текста.\n",
        "* Если n = 1 - то мы смотрим на то, сколько раз каждое слово встретилось в тексте. Получаем _униграммы_\n",
        "* Если n = 2 - то мы смотрим на то, сколько раз каждая пара подряд идущих слов, встретилась в тексте. Получаем _биграммы_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quiUoyqNb3WA"
      },
      "source": [
        "**Функция** для работы с n-граммами реализована в библиотке **nltk** (Natural Language ToolKit), импортируем эту функцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcrWxBzzWg-K"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ib-zYTvfQq5"
      },
      "source": [
        "Прежде чем получать n-граммы, нужно разделить предложение на отдельные слова.  Для этого используем метод ```split()```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2Ql8Em4Wg-N",
        "outputId": "73836765-1012-48d7-9acf-1ca307059d5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Если', 'б', 'мне', 'платили', 'каждый', 'раз']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "sentence = 'Если б мне платили каждый раз'.split()\n",
        "sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6V5P2Jcc4Oy"
      },
      "source": [
        "Чтобы получить n-грамму для такой последовательности, используем функцию ```ngrams()```.\n",
        "\n",
        "На вход передается два параметра:\n",
        "* лист с разделенным на отдельные слова предложением (у нас он хранится в переменной ```sent```);\n",
        "* параметр n, определяющий, какой тип n-грамм мы хотим получить.\n",
        "\n",
        "\n",
        "Чтобы полученный объект отобразить, делаем из него ```list```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9oqpykUc5e9",
        "outputId": "9429bff3-f723-4945-a761-020755fca8da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "list(ngrams(sentence, 1)) # униграммы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZKRhRlxfoj4"
      },
      "source": [
        "Аналогично мы можем получить биграммы - для этого заменяем параметр **n** в функции **ngrams** с 1 на 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzl6t5dpWg-P",
        "outputId": "41263c0f-490e-4f0a-88c2-1ff9cecddf11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "list(ngrams(sentence, 2)) # биграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCkkFzWLWg-R",
        "outputId": "bea40029-8bfd-49a5-d4db-0687cd376edb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "list(ngrams(sentence, 3)) # триграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GygS6_fJWg-S",
        "outputId": "0ab5bd36-00af-40e3-f2dc-15be32e528e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "list(ngrams(sentence, 5)) # ... пентаграммы?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JewKs4XU-so"
      },
      "source": [
        "### Векторизаторы\n",
        "\n",
        "Векторизатор преобразует слово или набор слов в числовой вектор, понятный алгоритму машинного обучения, который привык работать с числовыми табличными данными.\n",
        "\n",
        "Ниже - пример преобразования слов в двумерных вектор, каждому слову соответствует точка на плоскости.\n",
        "\n",
        "<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n",
        "\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\"\n",
        "alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hiNv2eVAc-"
      },
      "source": [
        "На начальном этапе нам будет достаточно тех инструментов, которые уже есть в знакомой нам библиотеке **sklearn**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPplZnxeVEBR"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer # модель \"мешка слов\", см. далее"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBN16KYZWg-U"
      },
      "source": [
        "Самый простой способ извлечь признаки из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
        "\n",
        "Объект `CountVectorizer` делает следующую вещь:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
        "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ\n",
        "\n",
        "<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n",
        "\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1jHmkrGZTMawM46Yzxh243Ur1y5pYKzrl\"\n",
        "alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oklbwY_vWg-X"
      },
      "source": [
        "На рисунке пример векторизации для униграмм, но можно использовать любые n-граммы. Для этого у объекта ```CountVectorizer()``` есть параметр **ngram_range**, который отвечает за то, какие n-граммы мы используем в качестве признаов:<br/>\n",
        "ngram_range=(1, 1) -- униграммы<br/>\n",
        "ngram_range=(3, 3) -- триграммы<br/>\n",
        "ngram_range=(1, 3) -- униграммы, биграммы и триграммы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjJmHbOvVmln"
      },
      "source": [
        "<a href=\"https://drive.google.com/uc?id=1ODNVK0fdLTX4nv6ob55ciUe37d1pio-D\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1ODNVK0fdLTX4nv6ob55ciUe37d1pio-D\"\n",
        "alt=\"IMAGE ALT TEXT HERE\" width=\"800\" border=\"0\" /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTEzNWxrx5X"
      },
      "source": [
        "Инициализируем ```CountVectorizer()```, указав в качестве признаков униграммы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWKQcLfBWg-W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "da1518c1-06d5-496a-c65b-b2891094ff00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-gFUNm6huAz"
      },
      "source": [
        "После инициализации _vectorizer_ можно обучить на наших данных.\n",
        "\n",
        "Для обучения используем обучающую выборку ```x_train```, но в отличие от классификатора мы используем метод ```fit_transform()```: сначала обучаем наш векторизатор, а потом сразу применяем его к нашему набору данных. Это похоже на то, как мы работали с label encoderом и one-hot-encoderом.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkJESwGfhq4v"
      },
      "outputs": [],
      "source": [
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoARhDzLsgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e923285d-e34c-4efd-8c65-b76113ddc1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<170125x243899 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1847652 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "vectorized_x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPJDPt7xvWKe"
      },
      "source": [
        "Так как результат не зависит от порядка слов в текстах, то говорят, что такая модель представления текстов в виде векторов получается из *гипотезы представления текста как мешка слов*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyT1Kz6Ppt8n"
      },
      "source": [
        "В vectorizer.vocabulary_ лежит словарь, отображение слов в их индексы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72knqTvCWg-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c05f7a6-6cb8-4894-ace2-b317f90421e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('везде', 111066),\n",
              " ('взрывают', 112239),\n",
              " ('помните', 188552),\n",
              " ('взрыв', 112225),\n",
              " ('на', 161864),\n",
              " ('марафоне', 156255),\n",
              " ('бостоне', 107900),\n",
              " ('но', 168704),\n",
              " ('два', 123853),\n",
              " ('почти', 191664)]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "list(vectorizer.vocabulary_.items())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKqMyRKjA-p"
      },
      "source": [
        "В нашей выборке 170125 текстов (твитов), в них встречается 243760 разных слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjOD7nrsi2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0f4a88-fcae-4151-9771-141c6dfe5419"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170125, 243899)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "vectorized_x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7geX_YHDjG9v"
      },
      "source": [
        "Так как теперь у нас есть **численное представление** и набор входных признаков, то мы можем обучить модель логистической регрессии (или любую другую из тех, на которые мы смотрели раньше, например, случайный лес)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCdROyxsWg-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2752267-6c5e-4d9d-dea7-2ebdf822d6d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170125, 243899)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "clf = LogisticRegression(random_state=random.randint(1,1000000), max_iter=1000)\n",
        "\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "\n",
        "print(vectorized_x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOhZqXVdd4BK",
        "outputId": "7ac476db-b18b-4edc-8890-638880e4858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170125,)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z9iIlzOjVUF"
      },
      "source": [
        "С тестовыми данными нужно проделать то же самое, что и с данными для обучения: сделать из текстов вектора, которые можно передавать в классификатор для прогноза класса объекта.\n",
        "\n",
        "У нас уже есть обученный векторизатор ```vectorizer```, поэтому используем метод ```transform()``` (просто применить его), а не ```fit_transform``` (обучить и применить)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2_AW8FpjWHQ"
      },
      "outputs": [],
      "source": [
        "vectorized_x_test = vectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahCRPAeWjtcl"
      },
      "source": [
        "Как раньше, для получения прогноза у обученного классификатора используем метод ```predict()```.\n",
        "\n",
        "С помощью функции ```classification_report()```, которая считает сразу несколько метрик качества классификации, посмотрим на то, насколько хорошо мы предсказываем положительную или отрицательную тональность твита ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juvxbzinWg-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2ef8a2-eb9f-4b06-804d-192d55c6f5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.77      0.76     27805\n",
            "    positive       0.77      0.76      0.77     28904\n",
            "\n",
            "    accuracy                           0.77     56709\n",
            "   macro avg       0.77      0.77      0.77     56709\n",
            "weighted avg       0.77      0.77      0.77     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yiLk1P_xYQ2"
      },
      "source": [
        "## Бонус*: триграммы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjy5ZPmwWg-j"
      },
      "source": [
        "Попробуем сделать то же самое, используя в качестве признаков триграммы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmQHqUpRWg-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2329bb76-335a-4a08-e00b-d54578e4fef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.85      0.68     27805\n",
            "    positive       0.72      0.38      0.50     28904\n",
            "\n",
            "    accuracy                           0.61     56709\n",
            "   macro avg       0.65      0.62      0.59     56709\n",
            "weighted avg       0.65      0.61      0.59     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# инициализируем векторайзер\n",
        "trigram_vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
        "\n",
        "\n",
        "# обучаем его и сразу применяем к x_train\n",
        "trigram_vectorized_x_train = trigram_vectorizer.fit_transform(x_train)\n",
        "\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "clf = LogisticRegression(random_state=random.randint(1,100000), max_iter=1000)\n",
        "clf.fit(trigram_vectorized_x_train, y_train)\n",
        "#\n",
        "# применяем обученный векторизатор к тестовым данным\n",
        "trigram_vectorized_x_test = trigram_vectorizer.transform(x_test)\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве\n",
        "pred = clf.predict(trigram_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MonLW7AyWg-m"
      },
      "source": [
        "Как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWxW3e9Wg-m"
      },
      "source": [
        "## Бонус**: TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7hCxZRtWg-m"
      },
      "source": [
        "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений выдает **tf-idf** каждого слова.\n",
        "\n",
        "Как считается tf-idf:\n",
        "\n",
        "**TF (term frequency)** – относительная частотность слова в документе:\n",
        "$$ TF(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n",
        "\n",
        "**IDF (inverse document frequency)** – обратная частота документов, в которых есть это слово:\n",
        "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
        "\n",
        "Перемножаем их:\n",
        "$$TFIDF(t, d, D) = TF(t,d) \\times IDF(i, D)$$\n",
        "\n",
        "Сакральный смысл: если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом\n",
        "количестве документов, у него высокий TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv7DfTkJWg-n"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02f_zZm14PHM"
      },
      "source": [
        "Действуем аналогично, как с ```CountVectorizer()```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjF9m3EOQTBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9db5a4c-594f-4564-86b0-1dbd08c5fee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.73      0.75     27805\n",
            "    positive       0.75      0.78      0.77     28904\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO #13\n",
        "\n",
        "# инициализируем векторизатор, в качестве переменных используем униграммы\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
        "\n",
        "# обучаем его и сразу применяем к x_train\n",
        "tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "clf = LogisticRegression(random_state=random.randint(1,100000), max_iter=1000)\n",
        "clf.fit(tfidf_vectorized_x_train, y_train)\n",
        "\n",
        "# применяем обученный векторизатор к тестовым данным\n",
        "tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве\n",
        "pred = clf.predict(tfidf_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rMYiobAWg-p"
      },
      "outputs": [],
      "source": [
        "# TODO #14\n",
        "\n",
        "# инициализируем векторизатор, в качестве переменных используем пентаграммы\n",
        "\n",
        "# обучаем его и сразу применяем к x_train\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "\n",
        "# применяем обученный векторизатор к тестовым данным\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D39SSh0zWg-r"
      },
      "source": [
        "## Токенизация\n",
        "\n",
        "Токенизировать - значит, поделить текст на части: слова, ключевые слова, фразы, символы и т.д., иными словами **токены**.\n",
        "\n",
        "Самый наивный способ токенизировать текст - разделить с помощью функции `split()`. Но `split` упускает очень много всего, например, не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем, поэтому лучше использовать готовые токенизаторы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoSe08N2Wg-r"
      },
      "outputs": [],
      "source": [
        "import nltk # уже знакомая нам библиотека nltk\n",
        "from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiDt3L8Y8god"
      },
      "source": [
        "Чтобы использовать токенизатор ```word_tokenize```, нужно сначала скачать данные для nltk о пунктуации и стоп-словах. Это просто требование nltk, поэтому, особо не задумываясь, запустите следующую ячейку:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPH3yMcumsdd",
        "outputId": "1e6c9989-4ce6-4c34-a058-f6f5e9354df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NfDb8D_9DqD"
      },
      "source": [
        "Применим токенизацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrJDGpgYWg-4",
        "outputId": "e18abbff-6cb1-4694-949b-5be03af44414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "example = 'Но не каждый хочет что-то исправлять:('\n",
        "word_tokenize(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxy7KGZI9bhK"
      },
      "source": [
        "Если использовать просто ```split()```, то грустный смайлик :( не отделяется от слова \"исправлять\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p52dIuSI9W6o",
        "outputId": "437f2443-fd83-48f4-c780-6cdd50e10e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять:(']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "example.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_702Dg5OWg-5"
      },
      "source": [
        "В nltk вообще есть довольно много токенизаторов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps8oPYoTWg-6",
        "outputId": "b693f51e-d4f7-4e2f-bae1-49724600bb74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LegalitySyllableTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'NLTKWordTokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'SyllableTokenizer',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer',\n",
              " 'TreebankWordDetokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "from nltk import tokenize\n",
        "dir(tokenize)[:16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnGCL5iWg-8"
      },
      "source": [
        "Они умеют выдавать индексы в строке для начала и конца каждого слова-токена:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jejj5X7QWg-8",
        "outputId": "48178e50-c423-4c09-d8d4-90092543d881"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "wh_tok = tokenize.WhitespaceTokenizer()\n",
        "list(wh_tok.span_tokenize(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-wf6A1EWg--"
      },
      "source": [
        "Некторые токенизаторы ведут себя специфично:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2REwpHGWWg-_",
        "outputId": "29f1329d-1576-4c17-9a30-53b97fcde613"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do', \"n't\", 'stop', 'me']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tckre90JWg_B"
      },
      "source": [
        "А некоторые -- вообще не для текста на естественном языке:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Ml3xtaWg_D",
        "outputId": "84f3601b-c6d5-47aa-bde5-17b8678c0a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(a (b c))', 'd', 'e', '(f)']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM2kvAo0_b93"
      },
      "source": [
        "**Правильный токенизатор подбирается исходя из требований задачи!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhVrgkSaWg_K"
      },
      "source": [
        "## Стоп-слова и пунктуация\n",
        "\n",
        "**Стоп-слова** - это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе. Для модели это просто шум. А шум нужно убирать. По аналогичной причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld-h6WKyWg_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52eca6c-7882-4c69-d29f-c276ca4bd6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        }
      ],
      "source": [
        "# импортируем стоп-слова из библиотеки nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# посмотрим на стоп-слова для русского языка\n",
        "print(stopwords.words('russian'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihn2Y_SzBU57"
      },
      "source": [
        "*Знаки* пунктуации лучше импортировать из модуля **String**. В нем хранятся различные наборы констант для работы со строками (пунктуация, алфавит и др.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x64U3FdPWg_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d393ea9-3ca2-404e-d86e-1cddc5b4bb22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9LGTLaEBwsC"
      },
      "source": [
        "Объединим стоп-слова и знаки пунктуации вместе и запишем в переменную ```noise```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfH5y50wWg_O"
      },
      "outputs": [],
      "source": [
        "noise = stopwords.words('russian')+ list(punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3gweXaWWg_P"
      },
      "source": [
        "Теперь нужно обучать нашу модель с учетом новых знаний про токенизацию и стоп-слова.\n",
        "\n",
        "Для этого мы можем собрать новый векторизатор, передав ему на вход:\n",
        "* какие n-граммы нам нужны, параметр **ngram_range**;\n",
        "* какой токенизатор мы используем, параметр **tokenizer**;\n",
        "* какие у нас стоп-слова, параметр **stop_words**.\n",
        "\n",
        "*Напоминание:* мы используем готовый токенизатор ```word_tokenize```, а стоп-слова хранятся в переменной ```noise```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbXrVeRRuAxx"
      },
      "outputs": [],
      "source": [
        "# инициализируем умный векторайзер\n",
        "smart_vectorizer = CountVectorizer(ngram_range=(1, 2), tokenizer=word_tokenize, stop_words=noise)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FZmY-ajvm6xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nc6D-nwWg_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb82f39-f6e7-42fa-f0d7-391f59129743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.81      0.79     27805\n",
            "    positive       0.81      0.76      0.79     28904\n",
            "\n",
            "    accuracy                           0.79     56709\n",
            "   macro avg       0.79      0.79      0.79     56709\n",
            "weighted avg       0.79      0.79      0.79     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# обучаем его и сразу применяем к x_train\n",
        "smart_vectorized_x_train = smart_vectorizer.fit_transform(x_train)\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "clf = LogisticRegression(random_state=random.randint(1,100000), max_iter=1000)\n",
        "clf.fit(smart_vectorized_x_train, y_train)\n",
        "\n",
        "# применяем обученный векторайзер к тестовым данным\n",
        "smart_vectorized_x_test = smart_vectorizer.transform(x_test)\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве\n",
        "pred = clf.predict(smart_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYWB1foQWg_T"
      },
      "source": [
        "Получилось лучше: accuracy выше, а также заметно подрос recall у негативного класса.\n",
        "\n",
        "Что ещё можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsRf9T_SWg_U"
      },
      "source": [
        "## Бонус*: Лемматизация\n",
        "\n",
        "**Лемматизация** – это сведение разных форм одного слова к начальной форме – **лемме**. Почему это хорошо?\n",
        "* Во-первых, естественно рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть хороших лемматизатор pymorphy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylKZG2MwWg_f"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcYWYq4BzOon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b76dd0-0e91-4777-94a8-f4cad3d02635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c408147c9a4b0dae51acba196b18510b59d458282caf2670fb43fb02db8c6a79\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "# устанавливаем pymorphy2\n",
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqdT2pmRFn2F"
      },
      "source": [
        "В pymorphy2 для морфологического анализа слов есть ```MorphAnalyzer()```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4nRuUu2Wg_g"
      },
      "outputs": [],
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egd6KdqzWg_h"
      },
      "source": [
        "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6hdm1KBFx18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8a0488-5089-47bb-a224-07bda7175271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Если', 'б', 'мне', 'платили', 'каждый', 'раз']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "sent = ['Если', 'б', 'мне', 'платили', 'каждый', 'раз']\n",
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr1C2beNF3vE"
      },
      "source": [
        "Лемматизируем слово \"платили\" из предложения ```sent``` с помощью метода ```parse()```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q3zNlPBWg_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8195a280-e4cf-4af6-92dd-326d69a174e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "ana = pymorphy2_analyzer.parse(sent[3])\n",
        "ana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2O2BL4_GJzq"
      },
      "source": [
        "Выведем его нормальную форму:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-zp0KZLWg_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c257e2d8-974f-4f2f-8067-3bf7f8cdf814"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'платить'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "ana[0].normal_form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hedBdcYWhAH"
      },
      "source": [
        "## О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом - главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhZMwsY5WhAI"
      },
      "outputs": [],
      "source": [
        "# TODO #19\n",
        "\n",
        "# инициализируем умный векторайзер stop-words НЕ ИСПОЛЬЗУЕМ!\n",
        "\n",
        "# обучаем его и сразу применяем к x_train\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "\n",
        "# применяем обученный векторайзер к тестовым данным\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSFebp_1WhAK"
      },
      "source": [
        "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEQbCtidWhAP"
      },
      "source": [
        "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhUG9qWuWhAQ"
      },
      "outputs": [],
      "source": [
        "# TODO #20\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrqW55jgWhAR"
      },
      "source": [
        "## Символьные n-граммы\n",
        "\n",
        "Теперь в качестве фичей используем, например, униграммы символов. Для этого необходимо установить в ```CountVectorizer()``` параметр ```analyzer = 'char'```, то есть анализировать символы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4lNhEmyWhAU"
      },
      "outputs": [],
      "source": [
        "# TODO #21\n",
        "\n",
        "# инициализируем векторайзер для символов\n",
        "\n",
        "# обучаем его и сразу применяем к x_train\n",
        "\n",
        "# инициализируем и обучаем классификатор\n",
        "\n",
        "# применяем обученный векторайзер к тестовым данным\n",
        "\n",
        "# получаем предсказания и выводим информацию о качестве"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLMMicsFWhAY"
      },
      "source": [
        "Из предыдущего раздела уже понятно, почему на этих данных точность равна 1.\n",
        "\n",
        "Символьные n-граммы используются, например, для задачи определения языка. Ещё одна замечательная особенность признаков-символов - для них не нужна токенизация и лемматизация, можно использовать такой подход для языков, у которых нет готовых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoWRUbZxMNv6"
      },
      "source": [
        "# Самостоятельная работа\n",
        "\n",
        "1. Изучите материал, представленный в борде.\n",
        "2. Выполните все ячейки и получите результаты.\n",
        "3. Приведите результаты таблицы classification_report в под этим заданием для модели LogisticRegression\n",
        "4. Примените 2 альтернативных использованному алгоритму для решения задачи классификации (для примера XGBClassifier и еще какой-то один) и получите результаты в таблице classification_report\n",
        "5. Для XGBClassifier вам потребуется задать параметры\n",
        "```learning_rate=0.1, n_estimators=1000, max_depth=5, min_child_weight=3, gamma=0.2, subsample=0.6, colsample_bytree=1.0, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27```\n",
        "\n",
        "6. В разделе TF-IDF векторизация по аналогии с униграммами и пентаграммами вычислите classification_report для биграмм, триграмм опубликуйте результаты в отчете и укажите изменилась ли точность f1-score при их использовании по сравнению с униграммами и пентаграммами."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zpq4QOU5Wg-H"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}